# Core dependencies
pandas>=1.5.0
requests>=2.28.0
python-dotenv>=0.19.0
numpy>=1.21.0

# Azure dependencies - Data Lake Gen2
azure-storage-file-datalake>=12.8.0
azure-identity>=1.12.0

# Azure dependencies - Data Factory Management
azure-mgmt-datafactory>=3.0.0
azure-mgmt-resource>=23.0.0

# Azure dependencies - SQL Database (optional for direct loading)
pyodbc>=4.0.39
sqlalchemy>=2.0.0

# Airflow dependencies
apache-airflow==2.7.3
apache-airflow-providers-postgres==5.6.0
psycopg2-binary>=2.9.0
Flask-Session>=0.5.0

# Development dependencies
pytest>=7.0.0
black>=22.0.0
flake8>=4.0.0




#######docker-compose up -d
# cd "c:\Users\David Ibanga\Data Engineering practicals\Urban_Cities_live_Service\notebook"; $env:PATH += ";C:\Program Files\Docker\Docker\resources\bin"; docker-compose up -d

# cd "c:\Users\David Ibanga\Data Engineering practicals\Urban_Cities_live_Service\notebook"; $env:PATH += ";C:\Program Files\Docker\Docker\resources\bin"; docker-compose run --rm airflow-webserver airflow db init
#cd "c:\Users\David Ibanga\Data Engineering practicals\Urban_Cities_live_Service\notebook"; Copy-Item "dag_script.py" "dags\nyc_311_dag.py" -Force
#cd "c:\Users\David Ibanga\Data Engineering practicals\Urban_Cities_live_Service\notebook"; $env:PATH += ";C:\Program Files\Docker\Docker\resources\bin"; docker-compose -f docker-compose-airflow.yml up -d
#cd "c:\Users\David Ibanga\Data Engineering practicals\Urban_Cities_live_Service\notebook"; $env:PATH += ";C:\Program Files\Docker\Docker\resources\bin"; docker-compose -f docker-compose-airflow.yml ps
#cd "c:\Users\David Ibanga\Data Engineering practicals\Urban_Cities_live_Service\notebook"; $env:PATH += ";C:\Program Files\Docker\Docker\resources\bin"; docker-compose -f docker-compose-airflow.yml logs airflow-webserver --tail=10
#cd "c:\Users\David Ibanga\Data Engineering practicals\Urban_Cities_live_Service\notebook"; Start-Sleep -Seconds 30; Write-Host "Checking if Airflow is ready..."; curl -s http://localhost:8080/health